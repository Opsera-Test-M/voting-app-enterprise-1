name: "Clean-It-All - Resource Cleanup"

on:
  workflow_dispatch:
    inputs:
      app_name:
        description: 'Application name'
        required: true
        type: string
        default: 'voting-app'
      tenant:
        description: 'Tenant name'
        required: true
        type: string
        default: 'opsera'
      environment:
        description: 'Environment to clean'
        required: true
        type: string
        default: 'dev'
      confirm_delete:
        description: 'Type DELETE to confirm (irreversible!)'
        required: true
        type: string

env:
  AWS_REGION: us-west-2
  APP_NAME: ${{ github.event.inputs.app_name }}
  TENANT: ${{ github.event.inputs.tenant }}
  ENVIRONMENT: ${{ github.event.inputs.environment }}
  DOMAIN: agent.opsera.dev
  HUB_CLUSTER: argocd-usw2
  SPOKE_CLUSTER: opsera-usw2-np

permissions:
  contents: write
  id-token: write

jobs:
  validate-confirmation:
    name: "Validate Confirmation"
    runs-on: ubuntu-latest
    steps:
      - name: Check Confirmation
        run: |
          if [ "${{ github.event.inputs.confirm_delete }}" != "DELETE" ]; then
            echo "ERROR: You must type DELETE to confirm cleanup"
            echo "This is a safety measure to prevent accidental deletions"
            exit 1
          fi
          echo "Confirmation received. Proceeding with cleanup..."

  capture-learnings:
    name: "Capture Deployment Learnings"
    runs-on: ubuntu-latest
    needs: [validate-confirmation]
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT || secrets.GITHUB_TOKEN }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Capture Learnings
        run: |
          LEARNINGS_FILE=".opsera-${{ env.APP_NAME }}/DEPLOYMENT-LEARNINGS.md"
          SUBDOMAIN="${{ env.TENANT }}-${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}.${{ env.DOMAIN }}"

          mkdir -p "$(dirname $LEARNINGS_FILE)"

          cat > "$LEARNINGS_FILE" << 'EOF'
          # Deployment Learnings - ${{ env.APP_NAME }}

          ## Deployment Info
          - **Application**: ${{ env.APP_NAME }}
          - **Tenant**: ${{ env.TENANT }}
          - **Environment**: ${{ env.ENVIRONMENT }}
          - **Region**: ${{ env.AWS_REGION }}
          - **Subdomain**: ${SUBDOMAIN}
          - **Cleaned Up**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")

          ## Architecture
          - 5 microservices: vote, result, worker, redis, postgres
          - Hub-Spoke EKS architecture
          - GitOps with ArgoCD
          - HTTPS with cert-manager + Let's Encrypt

          ## What Worked Well
          - (Add your notes here)

          ## Challenges Encountered
          - (Add your notes here)

          ## Recommendations for Next Time
          - (Add your notes here)
          EOF

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "$LEARNINGS_FILE"
          git commit -m "docs: capture deployment learnings before cleanup [skip ci]" || echo "No changes"
          git push origin main

  cleanup-kubernetes:
    name: "Cleanup Kubernetes Resources"
    runs-on: ubuntu-latest
    needs: [capture-learnings]
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Delete ArgoCD Application
        run: |
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl
          KUBECTL="./kubectl"

          # Connect to hub cluster
          aws eks update-kubeconfig --name ${{ env.HUB_CLUSTER }} --region ${{ env.AWS_REGION }} || {
            echo "Hub cluster not found"
            exit 0
          }

          APP_NAME="${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}"

          # Delete ArgoCD application
          if $KUBECTL get application "$APP_NAME" -n argocd 2>/dev/null; then
            $KUBECTL delete application "$APP_NAME" -n argocd
            echo "Deleted ArgoCD application: $APP_NAME"
          fi

          # Delete repo secret
          if $KUBECTL get secret "repo-${{ env.APP_NAME }}" -n argocd 2>/dev/null; then
            $KUBECTL delete secret "repo-${{ env.APP_NAME }}" -n argocd
            echo "Deleted repository secret"
          fi

      - name: Delete Namespace on Spoke
        run: |
          KUBECTL="./kubectl"
          NAMESPACE="${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}"

          # Connect to spoke cluster
          aws eks update-kubeconfig --name ${{ env.SPOKE_CLUSTER }} --region ${{ env.AWS_REGION }} || {
            echo "Spoke cluster not found"
            exit 0
          }

          # Delete namespace (cascades to all resources)
          if $KUBECTL get namespace "$NAMESPACE" 2>/dev/null; then
            $KUBECTL delete namespace "$NAMESPACE" --timeout=5m
            echo "Deleted namespace: $NAMESPACE"
          fi

  cleanup-ecr:
    name: "Cleanup ECR Repositories"
    runs-on: ubuntu-latest
    needs: [cleanup-kubernetes]
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Delete ECR Repositories
        run: |
          for SERVICE in vote result worker; do
            if aws ecr describe-repositories --repository-names "$SERVICE" 2>/dev/null; then
              # Force delete (removes all images)
              aws ecr delete-repository \
                --repository-name "$SERVICE" \
                --force || echo "Failed to delete $SERVICE repository"
              echo "Deleted ECR repository: $SERVICE"
            else
              echo "ECR repository $SERVICE not found"
            fi
          done

  cleanup-dns:
    name: "Cleanup DNS Records"
    runs-on: ubuntu-latest
    needs: [cleanup-kubernetes]
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Delete Route53 Records
        run: |
          SUBDOMAIN="${{ env.TENANT }}-${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}.${{ env.DOMAIN }}"

          # Get hosted zone ID
          HOSTED_ZONE_ID=$(aws route53 list-hosted-zones-by-name \
            --dns-name "${{ env.DOMAIN }}" \
            --query "HostedZones[?Name=='${{ env.DOMAIN }}.'].Id" \
            --output text | sed 's|/hostedzone/||')

          if [ -z "$HOSTED_ZONE_ID" ]; then
            echo "Hosted zone not found"
            exit 0
          fi

          # Get all records for this subdomain
          RECORDS=$(aws route53 list-resource-record-sets \
            --hosted-zone-id "$HOSTED_ZONE_ID" \
            --query "ResourceRecordSets[?Name=='${SUBDOMAIN}.']" \
            --output json)

          RECORD_COUNT=$(echo "$RECORDS" | jq 'length')

          if [ "$RECORD_COUNT" -gt 0 ]; then
            # Build delete batch
            DELETE_BATCH=$(echo "$RECORDS" | jq '{Changes: [.[] | {Action: "DELETE", ResourceRecordSet: .}]}')

            aws route53 change-resource-record-sets \
              --hosted-zone-id "$HOSTED_ZONE_ID" \
              --change-batch "$DELETE_BATCH"

            echo "Deleted $RECORD_COUNT DNS record(s) for $SUBDOMAIN"
          else
            echo "No DNS records found for $SUBDOMAIN"
          fi

  cleanup-summary:
    name: "Cleanup Summary"
    runs-on: ubuntu-latest
    needs: [cleanup-kubernetes, cleanup-ecr, cleanup-dns]
    if: always()
    steps:
      - name: Generate Summary
        run: |
          SUBDOMAIN="${{ env.TENANT }}-${{ env.APP_NAME }}-${{ env.ENVIRONMENT }}.${{ env.DOMAIN }}"

          echo "## Cleanup Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Resources Deleted" >> $GITHUB_STEP_SUMMARY
          echo "| Resource | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| ArgoCD Application | ${{ needs.cleanup-kubernetes.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Kubernetes Namespace | ${{ needs.cleanup-kubernetes.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| ECR Repositories | ${{ needs.cleanup-ecr.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| DNS Records | ${{ needs.cleanup-dns.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Configuration Cleaned" >> $GITHUB_STEP_SUMMARY
          echo "- Application: ${{ env.APP_NAME }}" >> $GITHUB_STEP_SUMMARY
          echo "- Environment: ${{ env.ENVIRONMENT }}" >> $GITHUB_STEP_SUMMARY
          echo "- Subdomain: ${SUBDOMAIN}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Deployment learnings saved to \`.opsera-${{ env.APP_NAME }}/DEPLOYMENT-LEARNINGS.md\`" >> $GITHUB_STEP_SUMMARY
